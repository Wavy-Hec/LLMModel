{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 7893,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03800836183960471,
      "grad_norm": 19.53653335571289,
      "learning_rate": 2.5063291139240508e-06,
      "loss": 7.5795,
      "step": 100
    },
    {
      "epoch": 0.07601672367920942,
      "grad_norm": 8.367148399353027,
      "learning_rate": 5.037974683544305e-06,
      "loss": 3.9454,
      "step": 200
    },
    {
      "epoch": 0.11402508551881414,
      "grad_norm": 1.5496808290481567,
      "learning_rate": 7.569620253164558e-06,
      "loss": 0.675,
      "step": 300
    },
    {
      "epoch": 0.15203344735841884,
      "grad_norm": 2.2599687576293945,
      "learning_rate": 1.0101265822784812e-05,
      "loss": 0.6519,
      "step": 400
    },
    {
      "epoch": 0.19004180919802358,
      "grad_norm": 1.3577570915222168,
      "learning_rate": 1.2632911392405064e-05,
      "loss": 0.6376,
      "step": 500
    },
    {
      "epoch": 0.22805017103762829,
      "grad_norm": 5.000295162200928,
      "learning_rate": 1.5164556962025319e-05,
      "loss": 0.6282,
      "step": 600
    },
    {
      "epoch": 0.26605853287723297,
      "grad_norm": 2.1696255207061768,
      "learning_rate": 1.7696202531645573e-05,
      "loss": 0.5687,
      "step": 700
    },
    {
      "epoch": 0.3040668947168377,
      "grad_norm": 7.928072929382324,
      "learning_rate": 1.9974658594959878e-05,
      "loss": 0.6364,
      "step": 800
    },
    {
      "epoch": 0.34207525655644244,
      "grad_norm": 19.99245834350586,
      "learning_rate": 1.969308742784739e-05,
      "loss": 0.5692,
      "step": 900
    },
    {
      "epoch": 0.38008361839604715,
      "grad_norm": 1.0809686183929443,
      "learning_rate": 1.94115162607349e-05,
      "loss": 0.4487,
      "step": 1000
    },
    {
      "epoch": 0.41809198023565186,
      "grad_norm": 148.05831909179688,
      "learning_rate": 1.9129945093622414e-05,
      "loss": 0.3903,
      "step": 1100
    },
    {
      "epoch": 0.45610034207525657,
      "grad_norm": 1.4990414381027222,
      "learning_rate": 1.8848373926509927e-05,
      "loss": 0.4224,
      "step": 1200
    },
    {
      "epoch": 0.4941087039148613,
      "grad_norm": 12.116073608398438,
      "learning_rate": 1.856680275939744e-05,
      "loss": 0.4073,
      "step": 1300
    },
    {
      "epoch": 0.5321170657544659,
      "grad_norm": 2.2031567096710205,
      "learning_rate": 1.828523159228495e-05,
      "loss": 0.3818,
      "step": 1400
    },
    {
      "epoch": 0.5701254275940707,
      "grad_norm": 0.7974539399147034,
      "learning_rate": 1.8003660425172466e-05,
      "loss": 0.419,
      "step": 1500
    },
    {
      "epoch": 0.6081337894336754,
      "grad_norm": 2.4825618267059326,
      "learning_rate": 1.7722089258059976e-05,
      "loss": 0.4018,
      "step": 1600
    },
    {
      "epoch": 0.6461421512732801,
      "grad_norm": 3.976482391357422,
      "learning_rate": 1.744051809094749e-05,
      "loss": 0.3787,
      "step": 1700
    },
    {
      "epoch": 0.6841505131128849,
      "grad_norm": 0.9964657425880432,
      "learning_rate": 1.7158946923835002e-05,
      "loss": 0.3515,
      "step": 1800
    },
    {
      "epoch": 0.7221588749524895,
      "grad_norm": 3.9888880252838135,
      "learning_rate": 1.6877375756722515e-05,
      "loss": 0.3961,
      "step": 1900
    },
    {
      "epoch": 0.7601672367920943,
      "grad_norm": 1.4114468097686768,
      "learning_rate": 1.6595804589610025e-05,
      "loss": 0.4061,
      "step": 2000
    },
    {
      "epoch": 0.798175598631699,
      "grad_norm": 4.746819972991943,
      "learning_rate": 1.6314233422497538e-05,
      "loss": 0.3691,
      "step": 2100
    },
    {
      "epoch": 0.8361839604713037,
      "grad_norm": 1.3025015592575073,
      "learning_rate": 1.603266225538505e-05,
      "loss": 0.3684,
      "step": 2200
    },
    {
      "epoch": 0.8741923223109084,
      "grad_norm": 2.163548231124878,
      "learning_rate": 1.5751091088272564e-05,
      "loss": 0.43,
      "step": 2300
    },
    {
      "epoch": 0.9122006841505131,
      "grad_norm": 2.4162349700927734,
      "learning_rate": 1.5469519921160074e-05,
      "loss": 0.3467,
      "step": 2400
    },
    {
      "epoch": 0.9502090459901178,
      "grad_norm": 1.469631314277649,
      "learning_rate": 1.5187948754047588e-05,
      "loss": 0.3535,
      "step": 2500
    },
    {
      "epoch": 0.9882174078297226,
      "grad_norm": 0.6699356436729431,
      "learning_rate": 1.49063775869351e-05,
      "loss": 0.3638,
      "step": 2600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8601558046741402,
      "eval_f1": 0.8531977037900326,
      "eval_loss": 0.3678271770477295,
      "eval_runtime": 107.3442,
      "eval_samples_per_second": 49.029,
      "eval_steps_per_second": 6.13,
      "step": 2631
    },
    {
      "epoch": 1.0262257696693273,
      "grad_norm": 5.110599040985107,
      "learning_rate": 1.4624806419822611e-05,
      "loss": 0.3252,
      "step": 2700
    },
    {
      "epoch": 1.0642341315089319,
      "grad_norm": 0.5283531546592712,
      "learning_rate": 1.4343235252710124e-05,
      "loss": 0.3377,
      "step": 2800
    },
    {
      "epoch": 1.1022424933485366,
      "grad_norm": 1.4235479831695557,
      "learning_rate": 1.4061664085597636e-05,
      "loss": 0.3512,
      "step": 2900
    },
    {
      "epoch": 1.1402508551881414,
      "grad_norm": 1.1761754751205444,
      "learning_rate": 1.3780092918485149e-05,
      "loss": 0.3733,
      "step": 3000
    },
    {
      "epoch": 1.1782592170277462,
      "grad_norm": 0.6486063599586487,
      "learning_rate": 1.349852175137266e-05,
      "loss": 0.3411,
      "step": 3100
    },
    {
      "epoch": 1.2162675788673507,
      "grad_norm": 0.8420780897140503,
      "learning_rate": 1.3216950584260173e-05,
      "loss": 0.3586,
      "step": 3200
    },
    {
      "epoch": 1.2542759407069555,
      "grad_norm": 1.0421451330184937,
      "learning_rate": 1.2935379417147684e-05,
      "loss": 0.3328,
      "step": 3300
    },
    {
      "epoch": 1.2922843025465602,
      "grad_norm": 1.0420407056808472,
      "learning_rate": 1.2653808250035198e-05,
      "loss": 0.3356,
      "step": 3400
    },
    {
      "epoch": 1.330292664386165,
      "grad_norm": 1.9085700511932373,
      "learning_rate": 1.2372237082922709e-05,
      "loss": 0.351,
      "step": 3500
    },
    {
      "epoch": 1.3683010262257698,
      "grad_norm": 0.7475090622901917,
      "learning_rate": 1.2090665915810222e-05,
      "loss": 0.3377,
      "step": 3600
    },
    {
      "epoch": 1.4063093880653743,
      "grad_norm": 1.9172443151474,
      "learning_rate": 1.1809094748697733e-05,
      "loss": 0.3541,
      "step": 3700
    },
    {
      "epoch": 1.444317749904979,
      "grad_norm": 1.2843555212020874,
      "learning_rate": 1.1527523581585246e-05,
      "loss": 0.3377,
      "step": 3800
    },
    {
      "epoch": 1.4823261117445838,
      "grad_norm": 1.0852164030075073,
      "learning_rate": 1.1245952414472758e-05,
      "loss": 0.3402,
      "step": 3900
    },
    {
      "epoch": 1.5203344735841884,
      "grad_norm": 1.2781221866607666,
      "learning_rate": 1.0964381247360273e-05,
      "loss": 0.382,
      "step": 4000
    },
    {
      "epoch": 1.5583428354237934,
      "grad_norm": 2.5590827465057373,
      "learning_rate": 1.0682810080247782e-05,
      "loss": 0.3429,
      "step": 4100
    },
    {
      "epoch": 1.596351197263398,
      "grad_norm": 0.8253835439682007,
      "learning_rate": 1.0401238913135297e-05,
      "loss": 0.3534,
      "step": 4200
    },
    {
      "epoch": 1.6343595591030027,
      "grad_norm": 1.5105394124984741,
      "learning_rate": 1.0119667746022808e-05,
      "loss": 0.3847,
      "step": 4300
    },
    {
      "epoch": 1.6723679209426074,
      "grad_norm": 1.0828485488891602,
      "learning_rate": 9.83809657891032e-06,
      "loss": 0.3445,
      "step": 4400
    },
    {
      "epoch": 1.710376282782212,
      "grad_norm": 5.393174648284912,
      "learning_rate": 9.556525411797833e-06,
      "loss": 0.3629,
      "step": 4500
    },
    {
      "epoch": 1.7483846446218168,
      "grad_norm": 1.1443934440612793,
      "learning_rate": 9.274954244685344e-06,
      "loss": 0.3689,
      "step": 4600
    },
    {
      "epoch": 1.7863930064614215,
      "grad_norm": 1.8927346467971802,
      "learning_rate": 8.993383077572857e-06,
      "loss": 0.349,
      "step": 4700
    },
    {
      "epoch": 1.824401368301026,
      "grad_norm": 1.5769765377044678,
      "learning_rate": 8.711811910460369e-06,
      "loss": 0.3517,
      "step": 4800
    },
    {
      "epoch": 1.862409730140631,
      "grad_norm": 0.6396881937980652,
      "learning_rate": 8.430240743347882e-06,
      "loss": 0.3537,
      "step": 4900
    },
    {
      "epoch": 1.9004180919802356,
      "grad_norm": 1.1644123792648315,
      "learning_rate": 8.148669576235393e-06,
      "loss": 0.3365,
      "step": 5000
    },
    {
      "epoch": 1.9384264538198404,
      "grad_norm": 0.6607411503791809,
      "learning_rate": 7.867098409122906e-06,
      "loss": 0.3745,
      "step": 5100
    },
    {
      "epoch": 1.9764348156594451,
      "grad_norm": 1.7246499061584473,
      "learning_rate": 7.5855272420104185e-06,
      "loss": 0.346,
      "step": 5200
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8614858445753373,
      "eval_f1": 0.8546672049632441,
      "eval_loss": 0.3784739375114441,
      "eval_runtime": 114.7631,
      "eval_samples_per_second": 45.86,
      "eval_steps_per_second": 5.734,
      "step": 5262
    },
    {
      "epoch": 2.0144431774990497,
      "grad_norm": 3.64750599861145,
      "learning_rate": 7.303956074897931e-06,
      "loss": 0.3626,
      "step": 5300
    },
    {
      "epoch": 2.0524515393386547,
      "grad_norm": 1.530028223991394,
      "learning_rate": 7.022384907785443e-06,
      "loss": 0.3299,
      "step": 5400
    },
    {
      "epoch": 2.090459901178259,
      "grad_norm": 1.2089393138885498,
      "learning_rate": 6.740813740672956e-06,
      "loss": 0.4302,
      "step": 5500
    },
    {
      "epoch": 2.1284682630178637,
      "grad_norm": 1.3891197443008423,
      "learning_rate": 6.459242573560468e-06,
      "loss": 0.3448,
      "step": 5600
    },
    {
      "epoch": 2.1664766248574687,
      "grad_norm": 1.0440586805343628,
      "learning_rate": 6.1776714064479805e-06,
      "loss": 0.3365,
      "step": 5700
    },
    {
      "epoch": 2.2044849866970733,
      "grad_norm": 0.9960674047470093,
      "learning_rate": 5.896100239335493e-06,
      "loss": 0.3286,
      "step": 5800
    },
    {
      "epoch": 2.2424933485366783,
      "grad_norm": 1.5374982357025146,
      "learning_rate": 5.614529072223005e-06,
      "loss": 0.3484,
      "step": 5900
    },
    {
      "epoch": 2.280501710376283,
      "grad_norm": 1.351328730583191,
      "learning_rate": 5.332957905110517e-06,
      "loss": 0.3462,
      "step": 6000
    },
    {
      "epoch": 2.3185100722158873,
      "grad_norm": 2.4584574699401855,
      "learning_rate": 5.051386737998029e-06,
      "loss": 0.3468,
      "step": 6100
    },
    {
      "epoch": 2.3565184340554923,
      "grad_norm": 1.2021664381027222,
      "learning_rate": 4.769815570885542e-06,
      "loss": 0.336,
      "step": 6200
    },
    {
      "epoch": 2.394526795895097,
      "grad_norm": 7.444609642028809,
      "learning_rate": 4.488244403773054e-06,
      "loss": 0.3606,
      "step": 6300
    },
    {
      "epoch": 2.4325351577347014,
      "grad_norm": 2.531918525695801,
      "learning_rate": 4.206673236660566e-06,
      "loss": 0.3621,
      "step": 6400
    },
    {
      "epoch": 2.4705435195743064,
      "grad_norm": 11.191094398498535,
      "learning_rate": 3.925102069548078e-06,
      "loss": 0.3816,
      "step": 6500
    },
    {
      "epoch": 2.508551881413911,
      "grad_norm": 1.404850721359253,
      "learning_rate": 3.643530902435591e-06,
      "loss": 0.3927,
      "step": 6600
    },
    {
      "epoch": 2.546560243253516,
      "grad_norm": 10.514628410339355,
      "learning_rate": 3.361959735323103e-06,
      "loss": 0.3506,
      "step": 6700
    },
    {
      "epoch": 2.5845686050931205,
      "grad_norm": 17.607975006103516,
      "learning_rate": 3.0803885682106154e-06,
      "loss": 0.3216,
      "step": 6800
    },
    {
      "epoch": 2.6225769669327255,
      "grad_norm": 0.417138934135437,
      "learning_rate": 2.798817401098128e-06,
      "loss": 0.3507,
      "step": 6900
    },
    {
      "epoch": 2.66058532877233,
      "grad_norm": 5.830815315246582,
      "learning_rate": 2.5172462339856403e-06,
      "loss": 0.3506,
      "step": 7000
    },
    {
      "epoch": 2.6985936906119345,
      "grad_norm": 1.7284977436065674,
      "learning_rate": 2.2356750668731525e-06,
      "loss": 0.3789,
      "step": 7100
    },
    {
      "epoch": 2.7366020524515395,
      "grad_norm": 0.5400773882865906,
      "learning_rate": 1.9541038997606647e-06,
      "loss": 0.3385,
      "step": 7200
    },
    {
      "epoch": 2.774610414291144,
      "grad_norm": 1.261154055595398,
      "learning_rate": 1.672532732648177e-06,
      "loss": 0.3457,
      "step": 7300
    },
    {
      "epoch": 2.8126187761307486,
      "grad_norm": 1.042417287826538,
      "learning_rate": 1.3909615655356892e-06,
      "loss": 0.3759,
      "step": 7400
    },
    {
      "epoch": 2.8506271379703536,
      "grad_norm": 1.005765676498413,
      "learning_rate": 1.1093903984232016e-06,
      "loss": 0.3715,
      "step": 7500
    },
    {
      "epoch": 2.888635499809958,
      "grad_norm": 1.0695399045944214,
      "learning_rate": 8.278192313107139e-07,
      "loss": 0.3336,
      "step": 7600
    },
    {
      "epoch": 2.9266438616495627,
      "grad_norm": 0.6550848484039307,
      "learning_rate": 5.462480641982262e-07,
      "loss": 0.2936,
      "step": 7700
    },
    {
      "epoch": 2.9646522234891677,
      "grad_norm": 0.8048510551452637,
      "learning_rate": 2.6467689708573845e-07,
      "loss": 0.2974,
      "step": 7800
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8390651719551586,
      "eval_f1": 0.8340494170391312,
      "eval_loss": 0.5687214732170105,
      "eval_runtime": 112.8813,
      "eval_samples_per_second": 46.624,
      "eval_steps_per_second": 5.829,
      "step": 7893
    }
  ],
  "logging_steps": 100,
  "max_steps": 7893,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4152953597114880.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
